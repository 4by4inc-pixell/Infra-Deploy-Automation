apiVersion: ray.io/v1
kind: RayCluster
metadata:
  name: raycluster
spec:
  # The version of Ray you are using. Make sure all Ray containers are running this version of Ray.
  # Use the Ray nightly or Ray version >= 2.10.0 and KubeRay 1.1.0 or later for autoscaler v2.
  rayVersion: '2.24.0'
  enableInTreeAutoscaling: true
  autoscalerOptions:
    upscalingMode: Default
    idleTimeoutSeconds: 60
    imagePullPolicy: IfNotPresent
    # Optionally specify the Autoscaler container's securityContext.
    securityContext: {}
    env: []
    envFrom: []
    resources:
      limits:
        cpu: "500m"
        memory: "512Mi"
      requests:
        cpu: "500m"
        memory: "512Mi"
  # Ray head pod template
  headGroupSpec:
    rayStartParams:
      # Setting "num-cpus: 0" to avoid any Ray actors or tasks being scheduled on the Ray head Pod.
      num-cpus: "0"
    # Pod template
    template:
      spec:
        containers:
        # The Ray head container
        - name: ray-head
          image: ghcr.io/4by4inc-pixell/pms-ray-cluster:0.2.2-basic
          ports:
          - containerPort: 6379
            name: gcs
          - containerPort: 8265
            name: dashboard
          - containerPort: 10001
            name: client
          lifecycle:
            preStop:
              exec:
                command: ["/bin/sh","-c","ray stop"]
          resources:
            limits:
              cpu: "4"
              memory: "8Gi"
            requests:
              cpu: "4"
              memory: "8Gi"
          env:
            # - name: RAY_DEDUP_LOGS
            #   value: "0"
            - name: RAY_enable_autoscaler_v2 # Pass env var for the autoscaler v2.
              value: "1"
        restartPolicy: Never # No restart to avoid reuse of pod for different ray nodes.
  workerGroupSpecs:
  # the Pod replicas in this group typed worker
  - replicas: 0
    minReplicas: 0
    maxReplicas: 20
    groupName: cpu-group
    rayStartParams: {}
    # Pod template
    template:
      spec:
        containers:
        - name: ray-worker-cpu
          image: ghcr.io/4by4inc-pixell/pms-ray-cluster:0.2.2-basic
          resources:
            limits:
              cpu: "3500m"
              memory: "1Gi"
            requests:
              cpu: "3500m"
              memory: "1Gi"
        restartPolicy: Never # Never restart a pod to avoid pod reuse
      
  - replicas: 0
    minReplicas: 0
    maxReplicas: 40
    groupName: gpu-group-s
    rayStartParams: {}
    # Pod template
    template:
      spec:
        containers:
        - name: ray-worker-gpu
          image: ghcr.io/4by4inc-pixell/pms-ray-cluster:0.2.2-trt
          resources:
            limits:
              cpu: "4"
              memory: "12Gi"
              nvidia.com/gpu: "1"
            requests:
              cpu: "1"
              memory: "1Gi"
              nvidia.com/gpu: "1"
        tolerations:
          - key: nvidia.com/gpu
            operator: "Exists"
            effect: "NoSchedule"
        restartPolicy: Never # Never restart a pod to avoid pod reuse
  
  - replicas: 0
    minReplicas: 0
    maxReplicas: 20
    groupName: gpu-group-m
    rayStartParams: {}
    # Pod template
    template:
      spec:
        containers:
        - name: ray-worker-gpu
          image: ghcr.io/4by4inc-pixell/pms-ray-cluster:0.2.2-trt
          resources:
            limits:
              cpu: "90"
              memory: "90Gi"
              nvidia.com/gpu: "4"
            requests:
              cpu: "4"
              memory: "4Gi"
              nvidia.com/gpu: "4"
        tolerations:
          - key: nvidia.com/gpu
            operator: "Exists"
            effect: "NoSchedule"
        restartPolicy: Never # Never restart a pod to avoid pod reuse
               
  - replicas: 0
    minReplicas: 0
    maxReplicas: 20
    groupName: gpu-group-l
    rayStartParams: {}
    # Pod template
    template:
      spec:
        containers:
        - name: ray-worker-gpu
          image: ghcr.io/4by4inc-pixell/pms-ray-cluster:0.2.2-trt
          resources:
            limits:
              cpu: "192"
              memory: "192Gi"
              nvidia.com/gpu: "8"
            requests:
              cpu: "8"
              memory: "8Gi"
              nvidia.com/gpu: "8"
        tolerations:
          - key: nvidia.com/gpu
            operator: "Exists"
            effect: "NoSchedule"
        restartPolicy: Never # Never restart a pod to avoid pod reuse
